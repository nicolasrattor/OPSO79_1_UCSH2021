---
title: "OPSO79-1-UCSH2021"
subtitle: "Inferencia desde muestras complejas en R: la lógica del muestreo y la inferencia"
date: "`26/11/2021`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [xaringan-themer.css]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
bibliography: "../../bibliografia/bib.bib"
---

```{r, load_refs, include=FALSE, cache=FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = "to.bib",
           dashed = FALSE)
bib <- ReadBib("../../bibliografia/bib.bib", check = FALSE)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(dplyr)
library(guaguas)

dark_yellow <- "#EFBE43"
light_yellow <- "#FDF7E9"
gray <- "#333333"
blue <- "#4466B0"

style_duo(
  # colors
  primary_color = light_yellow,
  secondary_color = dark_yellow,
  header_color = gray,
  text_color = gray,
  code_inline_color = colorspace::lighten(gray),
  text_bold_color = colorspace::lighten(gray),
  link_color = blue,
  title_slide_text_color = blue,

  # fonts
  header_font_google = google_font("Martel", "300", "400"),
  text_font_google = google_font("Lato"),
  code_font_google = google_font("Fira Mono")
)
```

```{r echo=FALSE,include=FALSE}
#library(pagedown)
#pagedown::chrome_print("clase11_muestreo.html")

```


class: inverse, center, middle

# La lógica del muestreo e inferencia


---

# Muestreo

Recursos limitados nos impiden encuestar a toda una población. 

--

Una salida es encuestar a una parte. ¿Que parte encuestar?, ¿A cuántas personas encuestar?

--

Si elegimos a la muestra de la forma correcta, podremos inferir hacia la población. 

--

Esta inferencia la haremos con un error conocido. 

--

Toda la lógica del muestreo es conocer y tratar de minimizar este error. 

--

```{r echo=FALSE, fig.align='center',out.width="30%"}
knitr::include_graphics('imagenes/population-sample.png')
```


---

# Un poco de nomenclatura

Para conocer los parámetros usamos estimadores. 

Con el estimador calculamos el parametro poblacional en base a una serie de datos
observados.

--

```{r echo=FALSE, fig.align='center',out.width="80%"}
knitr::include_graphics('imagenes/nomenclatura.png')
```


---

# Muestra

Para tener una **muestra estadísticamente representativa** el supuesto de la **muestra aleatoria** es fundamental

--

La selección aleatoria no supone que el grado de imprecisión asociado a las estimaciones sea necesariamente pequeño. Sí permite conocer la magnitud de la imprecisión.

--

Además, todos los elementos tienen una **probabilidad conocida y distinta de cero** de ser elegidos

--

Con esto, podemos conocer el error asociado a la estimación...

--

Y nos movemos dentro del mundo del **muestreo probabilísitico**

---

# Muestreo probabilístico

Sí tenemos un listado de los elementos (marco muestral), y seleccionamos aleatoriamente solamente algunos elementos a estudiar, estamos en un **muestreo probabilístico**. 

Esta es la base de otros diseños más complejos. 

--

La función teórica de la distribución normal nos permite establecer un intervalo
de posibles valores para nuestra estimación.

--

### Un ejemplo simple de selección aleatoria.

--

Creamos una base de datos de 19.678.363 casos, [el número de personas en Chile según el INE](https://www.ine.cl/estadisticas/sociales/demografia-y-vitales/proyecciones-de-poblacion), que contenga 1.492.522 extranjeros.

--

```{r}
poblacion<-data.frame(id=c(seq(1:19678363)),
                   extranjers=c(rep("ext",1492522),
                                rep("nac",19678363-1492522)))
```

---

# Muestreo probabilístico

```{r}
table(poblacion$extranjers)
prop.table(table(poblacion$extranjers))
```

---

# La selección aleatoria

Saquemos una muestra de 500, ¿qué % de extranjeros aparecerá?

--

```{r}
muestra<-sample_n(poblacion,500)
```

--

Y observamos su distribución:

```{r}
prop.table(table(muestra$extranjers)) 
```


---

# La selección aleatoria

¿Fue suerte?, veamos de nuevo...

--

```{r}
muestra<-sample_n(poblacion,500) 
prop.table(table(muestra$extranjers))  
```

--

De nuevo

```{r}
muestra<-sample_n(poblacion,500)
prop.table(table(muestra$extranjers))    
```

---

# La selección aleatoria

Cada vez que actualicemos esta presentación, la muestra seleccionada se nos va a modificar. 

--

Esto generará que cualquier análisis que queramos hacer con los datos no será reproducible, ya que cada vez que saquemos una muestra esta se modificará.

--

Manteniendo el azar, `R` nos permite fijar la selección aleatoria. Esto se logra "fijando una semilla".

--

```{r}
set.seed(17) ## número arbitrario   
```

Con esto, la distribución de la muestra que saquemos siempre será 0,064 (6,4%).

---

# La selección aleatoria

```{r}
muestra<-sample_n(poblacion,500)
prop.table(table(muestra$extranjers)) 
```

Efectivamente. Veamos de nuevo...

--

```{r}
set.seed(17)                                       
muestra<-sample_n(poblacion,500)
prop.table(table(muestra$extranjers))             
```


---

# La selección aleatoria

Las estimaciones que obtengamos de cada muestra de la población se ubicará en torno al parámetro poblacional. 

--

Ahora veremos que tan cierta es esta afirmación con 500 muestras

--

```{r}
set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:500),  # data vacía
                 ext=rep(NA,500),
                 nac=rep(NA,500))

# loop
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=500) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}   

baseinicial <- base

```

---

# La selección aleatoria

```{r}
head(baseinicial,10) %>% knitr::kable() 
```

---

# La selección aleatoria

¿El promedio del % de extranjeros entre todas las muestras?

--

```{r}
mean(baseinicial$ext)   ## OMG! en la población era 0.07584584   
```
--

Solo hay una diferencia de `r (mean(baseinicial$ext)-0.07584584)*100`% (menos de un 1%).


---

## La selección aleatoria

```{r echo=FALSE,warning=FALSE,message=FALSE, out.extra="25%", fig.align='center'}
library(ggplot2)
baseinicial %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkmagenta")+
  geom_vline(xintercept = mean(baseinicial$ext),
             linetype="dashed", color = "red") + 
  theme_bw() 

```

---

# La selección aleatoria

¿Que forma tiene la distribución?

--

Distribución teórica normal. ¿Y que sabemos de esta?

--

El el 68% de los casos se encuentran a +/- 1 SD del promedio, y el 95% a +/- 1.96 SD (puntaje Z)

--

```{r echo=FALSE, fig.align='center',out.width="50%"}
knitr::include_graphics('imagenes/normal.png')
```

---

# Estimar desde muestra

Además, mientras más muestras sacamos, más se distribuyen normal (**ley de los grandes números**)

--

Y mientras más grande es cada muestra de las muchas que saquemos, la distribución muestral de este del estadístico tenderá a ser normal (**Teorema del límite central**).

Las medias de muestras grandes y aleatorias son aproximadamente normales

--

Veamos ambas propiedades

---

## Ley de los grandes números

```{r fig.align='center', out.width="60%", echo=FALSE}
set.seed(1917)  # semilla

n1 <- 10
n2 <- 50
n3 <- 100
n4 <- 1000


base<-data.frame(muestra=c(1:n1),  # data vacía
                 ext=rep(NA,n1),
                 nac=rep(NA,n1))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=500) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot1 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw() + ggtitle("N=500, 10 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:n2),  # data vacía
                 ext=rep(NA,n2),
                 nac=rep(NA,n2))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=500) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot2 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw()  + ggtitle("N=500, 50 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:n3),  # data vacía
                 ext=rep(NA,n3),
                 nac=rep(NA,n3))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=500) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot3 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw() + ggtitle("N=500, 100 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:n4),  # data vacía
                 ext=rep(NA,n4),
                 nac=rep(NA,n4))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=500) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot4 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw()  + ggtitle("N=500, 1000 muestras")



library(gridExtra)
gridExtra::grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)

```


---

## Teorema del límite central

```{r fig.align='center', out.width="60%", echo=FALSE}
set.seed(1917)  # semilla

n1 <- 10
n2 <- 50
n3 <- 100
n4 <- 1000

base<-data.frame(muestra=c(1:500),  # data vacía
                 ext=rep(NA,500),
                 nac=rep(NA,500))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=n1) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot1 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw() + ggtitle("N=10, 500 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:500),  # data vacía
                 ext=rep(NA,500),
                 nac=rep(NA,500))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=n2) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot2 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw()  + ggtitle("N=50, 500 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:500),  # data vacía
                 ext=rep(NA,500),
                 nac=rep(NA,500))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=n3) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot3 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw() + ggtitle("N=100, 500 muestras")


set.seed(1917)  # semilla

base<-data.frame(muestra=c(1:500),  # data vacía
                 ext=rep(NA,500),
                 nac=rep(NA,500))
for(i in 1:nrow(base)){                      
  base[i,2:3]<-sample_n(poblacion,size=n4) %>% 
    select(extranjers) %>%  
    table() %>% prop.table()                       
}    
plot4 <- base %>% ggplot(aes(x=ext))+
  geom_histogram(fill="darkslategray3")+
  geom_vline(xintercept = mean(base$ext),
             linetype="dashed", color = "red") + theme_bw()  + ggtitle("N=1000, 500 muestras")



library(gridExtra)
gridExtra::grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)

```



---

# Estimar desde muestra

Conocemos la teoría de muestras y la demostramos sacando muchas muestras.

--

En la práctica solo tenemos recursos para seleccionar 1 muestra.

Desde los datos de esta muestra debemos **estimar** el valor que nos interesa de la población.

--

Cada % de extranjeros estimado con 1 muestra tiene un error asociado. 

--

Por ejemplo: *en la población se estiman entre un 6,5% y 8,5% de extranjeros*

--

Esta forma de medir el error utiliza un "intervalo de confianza" (+-1%)

---

# Estimar desde muestra

La teoría de muestras nos permite conocer este error, en base a:

+ tamaño de la muestra (n)

+ nivel de confianza en puntaje Z (z)

+ variabilidad de los datos (p(1-p))

--

$$[\overline{p} \pm z_{a/2}\sqrt\frac{\overline{p}(1-\overline{p})}{{n}}]$$
--

+ tamaño de la muestra: 500 observaciones

+ nivel de confianza en puntaje Z: 1,96

+ variabilidad de los datos: 6,4% (o lo que de la muestra)


---

# Estimar desde muestra

En simple, definamos objetos

```{r}
p <- as.vector(prop.table(table(muestra$extranjers)))[1]
n <- nrow(muestra)
z <- 1.96 # para 95% de confianza
```

--

Calculamos intervalo

```{r}
ci <- z * (sqrt(p*(1-p)/n))
ci
```
--

Con un 95% de confianza, y con una muestra probabilística de 500 observaciones, calculamos que el porcentaje de extranjeros en la población está entre `r p-ci` y `r p+ci` (`r p` $\pm$ `r ci`).

La estimación parecer ser correcta. En la población la proporción es 0.075

---

# Estimar desde muestra

¿Que significa el 95% de confianza?

--

Que si sacamos 20 muestras, las estimaciones desde una de estas no contendría dentro de sus intervalos el valor poblacional.

--

O que si sacamos 100 muestras, las estimaciones desde cinco de estas no contendría dentro de sus intervalos el valor poblacional.

--

```{r echo=FALSE, fig.align='center',out.width="50%"}
knitr::include_graphics('https://cdn-img.scalabs.com.au/uzjYWz5uFA99H9ilh_BLtPqAA1Dq0GhZ05-Iow7qAZM/aHR0cHM6Ly9zdy1o/aXQtcHJkLnNjYWRp/Z2l0YWwuaW8vbWVk/aWEvMTYyNjYvc2lk/ZS1leWUtY2hsb2Uu/anBnP3ByZXNldD1N/YWluSW1hZ2U')
```

--

Veamoslo con 20 de las 500 muestras que sacamos. 

---

# Estimar desde muestra

Calculamos los intervalos de confianza de cada muestra

```{r}
submuestra <- baseinicial[1:20,c(1,2)] %>% 
  rename(p=ext) %>% 
  mutate(limite_inferior= p - (z * (sqrt(p*(1-p)/n))),
         limite_superior= p + (z * (sqrt(p*(1-p)/n))))
```

```{r echo=FALSE}
submuestra[1:5,] %>% knitr::kable()
```

---

## Visualización estimaciones

```{r echo=FALSE, out.extra="20%", fig.align='center'}
ggplot(submuestra, aes(x=as.factor(muestra), y = p)) +
      geom_point() +
      geom_errorbar(data=submuestra, 
                    aes(ymin=limite_inferior, ymax=limite_superior)) +
  geom_hline(yintercept=0.07584584, linetype="dashed", color = "red") +
  theme_bw()
```




---

# Elementos a destacar

Vimos como estimar proporciones

Para estimar medias, medianas, varianzas y totales la formula debe ser ajustada. 

--

Para calcular los IC no hemos consideramos el tamaño de la población. 

¿No es relevante? Lo es, pero marginalmente

--

Lo que es más relevante es el tamaño de la muestra, nivel de confianza y variabilidad de los datos

--

Elementos que la formula ya vista resume y que podemos re estructurar para calcular el tamaño de una muestra (agregando tamaño de población):

$$n=(1-\frac{n}{N})*\frac{z^2_{a/2}(s^2)}{e^2}$$
--

Determinando un nivel de confianza (z), un error esperado (e), teniendo antecedentes de la variabilidad de los datos (s2) y conociendo el N de la población... podemos calcular una muestra. 

---

## Tamaño muestra y error

Si definimos errores elevados la muestra es pequeña.

--

```{r echo=FALSE, warning=FALSE, message=FALSE, out.width="50%", fig.align='center'}

library(samplingbook)

## Población 19 millones. 95% nivel de confianza.

d=(19000000*(1.96^2)*(0.5*0.5))
n=((5^2)*(19000000-1))+(1.96^2)*(0.5*0.5)
e<-d/n*10000

error<-c(0.35,0.4,0.45,0.5,1,1.5,2,2.5,3,3.5,4)
n<-c(rep(NA,length(error)))
base<-data.frame(error,n)


for(i in 1:nrow(base)){
  base[i,2]<-round((19000000*(1.96^2)*(0.5*0.5))/(((error[i]^2)*(19000000-1))+(1.96^2)*(0.5*0.5))*10000)
}

base %>% ggplot(aes(x=n,y=error))+geom_line()+geom_point() + theme_bw() + labs(title="Tamaño de muestra y error máximo admisible",y="Error (%)",x="Tamaño muestra",subtitle = "Un error de 3% es razonable (n=1067 al 95%)") + 
  scale_x_continuous(labels=function(x) format(x, big.mark = ".", scientific = FALSE))


```

---

## n muestra y nivel de confianza

```{r echo=FALSE, warning=FALSE, message=FALSE,  out.width="50%", fig.align='center'}
ncz<-c(1.64,1.96,2.58, 3, 3.5, 3.8)
nc<-c("90%","95%","99%","99,87%", "99,96%", "99,99%")
n<-c(rep(NA,length(ncz)))
base<-data.frame(nc,ncz,n)


for(i in 1:nrow(base)){
  base[i,3]<-round((19000000*(ncz[i]^2)*(0.5*0.5))/(((3^2)*(19000000-1))+(ncz[i]^2)*(0.5*0.5))*10000)
}

base %>% ggplot(aes(x=n,y=ncz))+geom_line()+geom_point() + theme_bw() + labs(title="Tamaño de muestra y nivel de confianza",y="Puntaje z",x="Tamaño muestra",subtitle = "Error max. admisible fijo en 3%") + 
  scale_x_continuous(labels=function(x) format(x, big.mark = ".", scientific = FALSE))

```

---

## n muestra y variabilidad

Se considra la varianza de una pregunta de investigación previa. A mayor varianza, más casos se necesitarán. Si no hay información se supone varianza máxima (`0.5^2`)

```{r echo=FALSE, warning=FALSE, message=FALSE,  out.width="50%", fig.align='center'}

P<-c(0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5)
n<-c(rep(NA,length(P)))
base<-data.frame(P,n)

for(i in 1:nrow(base)){
  
base[i,2]<-sample.size.prop(e=0.01, P = P[i], N = 100000, level = 0.95)$n

}

base %>% ggplot(aes(x=n,y=P))+geom_point()+geom_line() + theme_bw() + labs(title="Tamaño de muestra y varianza",y="Varianza",x="Tamaño muestra",subtitle = "Error max. admisible en 3%, 95% de confianza y población 100.000") + 
  scale_x_continuous(labels=function(x) format(x, big.mark = ".", scientific = FALSE))

```

---

## n muestra y N población

En poblaciones superiores a 100.000 casos la influencia del tamaño de la población es ínfima

```{r echo=FALSE, warning=FALSE, message=FALSE,  out.width="50%", fig.align='center'}
poblacion<-c(100,10000,50000,100000,200000,300000,500000,600000,700000,800000,900000,1000000)
n<-c(rep(NA,length(poblacion)))
base<-data.frame(poblacion,n)

library(samplingbook)

for(i in 1:nrow(base)){
  
base[i,2]<-sample.size.prop(e=0.01, P = 0.5, N = poblacion[i], level = 0.95)$n

}

base %>% ggplot(aes(y=n,x=poblacion))+geom_line()+geom_point() + theme_bw() + labs(title="Tamaño de muestra y de la poblacion",x="Tamaño población",y="Tamaño muestra",subtitle = "Error max. admisible en 3% y 95% de confianza") + 
  scale_y_continuous(labels=function(x) format(x, big.mark = ".", scientific = FALSE),limits = c(0,10000))+
    scale_x_continuous(labels=function(x) format(x, big.mark = ".", scientific = FALSE))



```

---

# Calcular muestras

Hay algunas páginas como [SurveyMonkey](https://www.surveymonkey.com/mp/sample-size-calculator/) o [Calculator](https://www.calculator.net/sample-size-calculator.html) desde donde se puede calcular el tamaño de una muestra en base a los criterios de la formula.

--

Acá utilizaremos un paquete para eso

```{r message=FALSE,warning=FALSE}
library(samplingbook)
```

--

Si tenemos variabilidad como proporción *dummy* (P)

```{r}
sample.size.prop(e=0.03, P = 0.75, N = 19000000, level = 0.95)
```

--

Si tenemos variabilidad de variable numérica (SD) (y no tenemos el N)

```{r eval=FALSE}
sample.size.mean(e=0.03, S = 0.5, N = Inf, level = 0.95)
```


---

class: inverse, center, middle

# Tipos de muestreo

`Presentación general del estratificado y por conglomerados`

---

# Muestreo

--

### Probabilístico

#### Muestreo aleatorio simple

#### Muestreo estratificado

#### Muestreo por conglomerados

--

### No probabilístico

#### Muestreo por cuotas (no lo veremos)

---

## Muestreo aleatorio simple (MAS)

Se deja actuar libremente al azar (con o **sin reemplazo**, unidades de la muestra distintas)

--

Sirve de referencia y base para los demás tipos de diseños

--

Es monetápica, autoponderada y equiprobable.

--

**Ventaja:**

1. Sencillez de las fórmulas.

2. Precisión de la estimación

--

**Desventaja:**

1. Necesitas el listado de todos los elementos (marco muestral)

2. Aumenta el error al estimar desagregaciones

--

Con diseños más complejos podemos mantener la misma precisión, pero necesitando menos elementos en la muestra e incluso no necesitar un marco muestral

---

## Marcos muestrales

La población esta claramente definida y acotada: alumnas/os del OPSOUCSH. 

--


En cambio, en relación al **marco muestral**, el listado de los elementos de la población, no tenemos la certeza de su cobertura, actualización, etc.

--

Siempre es necesario evaluar la calidad del marco muestral, dado que será la fuente de la
información.

--

Además, es relevante que se explicite como acceder a las unidades seleccionadas.

---

## Muestreo estratificado

Estrato: Grupo homogéneo de elementos compuesto por una variable auxiliar

--

Los estratos son diferentes entre si, la varianza dentro de los estratos es pequeña, pero entre los estratos es grande.

--

+ sector económico, región y rural/urbano

--

Agrupar en grupos homogéneos, aumenta la precisión de la estimación. 

Con esto, se puede asegurar precisión para cada estrato. 

--

La selección de elementos se realiza después de establecidos los estratos y asignado cada elemento al estrato de pertenencia.

--

Es clave contar con una variable de estratificación, que asigne un estrato a cada unidad. 

---

## Muestreo estratificado

Lo más básico es elegir para cada estrato un número proporcional de elementos (**Afijación proporcional**).

Si el estrato es más grande, debemos seleccionar más elementos de ese estrato

--

En la práctica esto nunca se hace. 

Se ocupa la **afijación óptima**. 

--

El tamaño de la muestra seleccionada para cada estrato varía proporcionalmente y por la varianza de cada estrato

Si el estrato es muy heterogéneo necesitamos más casos

--

Como resultado, nuestras distintas observaciones tendrán diferentes "pesos" por los estratos a los que pertenecen. 

Estrato pequeño y homogeneo tendrá pocos casos en la muestra, los que pesarán mucho (factor de expansión)


---

## Muestreo por conglomerados

--

Conglomerado: conjunto de elementos homogéneo entre sí y que se diferencia de otros conjuntos

--

La lógica aplicar dos veces el muestreo:

+ para seleccionar conglomerados a estudiar

+ para seleccionar a los elementos dentro de los conglomerados seleccionados

--

*"Los conglomerados son parecidos entre sí, por tanto se seleccionan sólo algunos para conformar la muestra. No se requiere de la lista de todos los elementos de la población, sólo el listado de elementos de los conglomerados elegidos."* (Vivanco, 2006: 144).

--

Si no se dispone del listado de elementos a encuestar se recomienda conglomerados.

--

Es más barato producir el marco muestral de los conglomerados seleccionados que de todos. 

--

Reduce los costos y recolección. Facilita supervisión.

--

Desventaja – incrementa el error de estimación (**efecto diseño**).

---

## Muestreo por conglomerados

En ciertas situaciones, las unidades muestrales están “agrupadas” en forma natural. 

--

Por ejemplo:

Viviendas de una ciudad – agrupadas en
Manzanas.

--

Alumnos de la Universidad – agrupados en
Facultades (o cursos).

--

Luteranos - agrupados en iglesias

--

Usuarios del metro – agrupados por horario-estación

--

CASEN y ENE


---

## Muestreos no probabilísticos

Se caracterizan por que los elementos **no** tienen una probabilidad conocida de
selección

--

Esto anula las herramientas elaboradas para inferir de la muestra a la población.

Es imposible conocer la magnitud del error.

--

El más común es el muestreo por cuotas

--

Se sustenta conceptualmente en que si se replican los porcentajes de la población, tendré una muestra representativa (**nunca estadísticamente**)

--

El trabajo del muestrista es establecer las cuotas. El del entrevistador llenarlas.

--

No requiere del marco muestral (listado de elementos)

Sesgo de participación (no todos los elementos tienen probabilidad de ser seccionados y tampoco se conoce esta probabilidad)

---

## Conclusiones

Para inferir estadísticamente necesitamos un muestreo probabilístico

--

+ Unidades elegidas aleatoriamente

+ Todas las unidades de la población tienen probabilidad conocida y distinta de cero de ser seleccionadas

--

Desafíos del terreno: calidad de respuestas, unidades no elegibles, no contacto y no respuesta

--

Inferir desde muestras seleccionadas con MAS puede ser relativamente simple (similar a como lo vimos acá)

--

Pero hacerlo desde muestreos más complejos como conglomerados y estratos, y cuando las unidades tienen diferentes probabilidades de selección, el tema se complica.

--

Ahí es cuando los paquetes `survey` y `srvyr` en `R` serán fundamentales ([próxima clase los veremos](https://opso791ucsh2021.netlify.app/clases/clase11/clase10b_survey))





---

### Recursos web utilizados

[Xaringan: Presentation Ninja, de Yihui Xie](https://github.com/yihui/xaringan). Para generar esta presentación.


### Bibliografía utilizada

```{r echo=FALSE, results=FALSE}
Citet(bib, "Lohr2000")
Citet(bib, "Vivanco2006")

```

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(bib)
```



